Important Docker Commands


- docker images
    + To list all the docker images present in the Docker server
- docker image inspect [image_id]
    + To display detailed image information for a given image id
- docker image rm [image_id]
    + To remove one or more images for a given image ids
- docker build . -t [image_name]
    + To generate a docker image based on a Dockerfile
- docker run -p [host_port]:[container_port] [image_name]
    + To start a docker container based on a given image
- docker ps
    + To show all running containers
- docker ps -a
    + To show all containers including running and stopped
- docker container start [container_id]
    + To start one or more stopped containers
- docker container pause [container_id]
    + To pause all processes within one or more containers
- docker container unpause [container_id]
    + To resume/unpause all processes within one or more containers
- docker container stop [container_id]
    + To stop one or more running containers
- docker container kill [container_id]
    + To kill one or more running containers instantly
- docker container restart [container_id]
    + To restart one or more containers
- docker container inspect [container_id]
    + To inspect all the details for a given container id
- docker container logs [container_id]
    + To fetch the logs of a given container id
- docker container logs -f [container_id]
    + To follow log output of a given container id
- docker rm [container_id]
    + To remove one or more containers based on container ids
- docker container prune
    + To remove all stopped containers
- docker image push [container_registry/username:tag]
    + To push an image from a container registry
- docker image pull [container_registry/username:tag]
    + To pull an image from a container registry
- docker image prune
    + To remove all unused images
- docker container stats
    + To show all containers statistics like CPU, memory, I/O usage
- Docker system prune
    + Remove stopped containers, dangling images, and unused networks, volumes, and cache
- docker rmi [image_id]
    + To remove one or more images based on image ids
- docker login -u [username]
    + To login in to docker hub container registry
- docker logout
    + To login out from docker hub container registry
- docker history [image_name]
    + Display the intermediate layers and commands that were executed when building the image
- docker exec -it [container_id] sh
    + To open a shell inside a running container and execute commands
- docker compose up
    + To create and start containers based on given docker compose file
- docker compose down
    + To stop and remove containers fro services defined in the Compose file

15 Factor Methodologies
- One codebase, one application
    + Each application has a dedicated codebase. Shared code is managed separately as a library, allowing it to be utilized as a dependency
    or as a standalone service, serving as a backing service for other applications. It is possible to track each codebase in its own repository,
    providing flexibility and organization.
    + In this methodology, a deployment refers to an operational instance of the application.
- API First
    + In a cloud-native ecosystem, a typical setup consists of various services that interact through APIs.
    Adopting an API-first approach during the design phase of a cloud-native application encourages a mindset
    with distributed systems and promotes the division of work among multiple teams.
- Dependency Management
    + It is crucial to explicitly declare all dependencies opf an application in a manifest and ensure that they are accessible to the
    dependency manager, which can download them from a central repository.
- Design, build, release, run
    + Design stage: Determine technologies, dependencies, and tools for specific application features.
    + Build stage:  Compile and package the codebase with dependencies, creating an immutable artifact(build). Unique identification
    of the build artifact is essential.
    + Release stage: Combine the build with a specific deployment configuration. Each release is immutable and uniquely identifiable,
    such as through semantic versioning or timestamp. Central repository storage facilitates easy access, including rollbacks if needed.
    + Run stage: Execute the application in the designated runtime environment using a specific release.
- Configuration, credentials & code
    + Configuration encompasses all elements prone to change between deployments. It emphasizes the ability to modify application configuration independently,
    without code changes or the need to rebuild the application.
    + Configuration may include resources handles for banking services, credentials for accessing third-party APIs, and feature flags.
- Logs
    + In a cloud-native application, log routing and storage are not hte application's concern. Instead, applications should direct their logs to the
    standard output, treating them as sequentially ordered events based on time.
    + The responsibility of log storage and rotation is now shifted to an external tool, known as a log aggregator.
- Disposability
    + During high-load periods, additional instances of the application can be spun up to handle the increased workload. This concept is referred to
    as application disposability, where applications can be started or stopped as needed.
- Backing Services
    + Backing services refer to external resources that an application relies on to provide its functionality. These resources can include databases,
    message brokers, caching systems, SMTP servers, FTP servers, or RESTful web services. By treating these services as attached resources, you can
    modify or replace them without needing to make changes to the application code.
- Environment Parity
    + Environment parity aims to minimize differences between various environments & avoiding costly shortcuts. Here, the adoption of containers
    can greatly contribute by promoting the same execution environment.
    + There are three gaps that this factor addresses:
        * Time gap: The time it takes for a code change to be deployed can be significant. The methodology encourages automation and continuous deployment
        to reduce the time between code development and production deployment.
        * People gap: Developers create applications, while operators handle their deployment in production. To bridge this gap,
        a DevOps culture promotes collaboration between developers and operators, fostering the "you build it, you run it" philosophy.
        * Tools gap: Handling of backing services differs across environments. For instance, developers might use the H2 database locally but PostgreSQL
        in production. To achieve environment parity, it is recommended to use the same type and version of backing services across all environments.
- Administrative Process
    + Management tasks required to support applications, such as database migrations, batch jobs, or maintenance tasks, should be treated as isolated processes.
    Similar to application processes, the code for these administrative tasks should be version controlled, packed alongside the application, and executed
    within the same environment
- Port binding
    + Cloud native applications, adhering to the 15-Factor methodology, should be self-contained and expose their services through port binding.
    In production environments, routing services may be employed to translate requests from public endpoints to the internally port-bound services.
- Stateless Processes
    + Cloud native applications are often developed with high scalability in mind. One of the key principles to achieve scalability is designing
    applications as stateless processes and adopting a share-noting architecture. This means that no state should be shared among different instances of the app.
- Concurrency
    + Scalability is not solely achieved by creating stateless applications. While statelessness is important, scalability also requires the ability
    to serve a larger number of users. This means that applications should support concurrent processing to handle multiple users simultaneously.
    + In JVM applications, concurrency is typically managed through the use of multiple threads, which are available from thread pools.
- Telemetry
    + Telemetry data, such as logs, metrics traces, health status, and events, plays a vital role in providing this visibility.
- Authentication and Authorization
    + Security is a critical aspect of a software system, yet it often doesn't receive the necessary emphasis it deserves. To uphold a zero-trust
    approach, it is essential to ensure the security of every interaction within the system, encompassing architectural and infrastructural levels.
    While security involves more than just authentication and authorization, these aspects serve as a solid starting point.


Activating the Profile Using Command-Line, JVM & Environment Options
Modify Run Configuration
+ Environment Variables:
    SPRING_PROFILES_ACTIVE=prod;BUILD_VERSION=1.4
+ VM Arguments
    -Dspring.profiles.active=prod -Dbuild.version=1.4
+ Program Arguments
    --spring.profiles.active=prod --build.version=1.4
- Priority Higher to Lower
1) Command Line Arguments has higher preference. (Program Arguments)
2) VM Options
3) Environment Variables